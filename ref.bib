@article{mali2015study,
  title={A study on statistical analysis and security evaluation parameters in image encryption},
  author={Mali, Kalyani and Chakraborty, Shouvik and Roy, Mousomi},
  journal={entropy},
  volume={34},
  pages={36},
  year={2015}
}

@inproceedings{bajard2016full,
  title={A full RNS variant of FV like somewhat homomorphic encryption schemes},
  author={Bajard, Jean-Claude and Eynard, Julien and Hasan, M Anwar and Zucca, Vincent},
  booktitle={International Conference on Selected Areas in Cryptography},
  pages={423--442},
  year={2016},
  organization={Springer}
}

@misc{liu2024pencilprivateextensiblecollaborative,
      title={Pencil: Private and Extensible Collaborative Learning without the Non-Colluding Assumption}, 
      author={Xuanqi Liu and Zhuotao Liu and Qi Li and Ke Xu and Mingwei Xu},
      year={2024},
      eprint={2403.11166},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2403.11166}, 
}

@ARTICLE{8611203,
  author={Wu, Haiqin and Wang, Liangmin and Xue, Guoliang},
  journal={IEEE Transactions on Network Science and Engineering}, 
  title={Privacy-Aware Task Allocation and Data Aggregation in Fog-Assisted Spatial Crowdsourcing}, 
  year={2020},
  volume={7},
  number={1},
  pages={589-602},
  keywords={Task analysis;Data aggregation;Sensors;Privacy;Resource management;Crowdsourcing;Servers;Spatial crowdsourcing;data aggregation;fog computing;bilinear pairing;homomorphic encryption},
  doi={10.1109/TNSE.2019.2892583}
}



@article{yang2021distributed,
  title={A distributed networked system for secure publicly verifiable self-tallying online voting},
  author={Yang, Xuechao and Yi, Xun and Kelarev, Andrei and Han, Fengling and Luo, Junwei},
  journal={Information Sciences},
  volume={543},
  pages={125--142},
  year={2021},
  publisher={Elsevier}
}



@article{xiao2017fashion,
  title={Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms},
  author={Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  journal={arXiv preprint arXiv:1708.07747},
  year={2017}
}



@article{kakkad2019biometric,
  title={Biometric authentication and image encryption for image security in cloud framework},
  author={Kakkad, Vishruti and Patel, Meshwa and Shah, Manan},
  journal={Multiscale and Multidisciplinary Modeling, Experiments and Design},
  volume={2},
  number={4},
  pages={233--248},
  year={2019},
  publisher={Springer}
}



@article{makridakis2017forthcoming,
  title={The forthcoming Artificial Intelligence (AI) revolution: Its impact on society and firms},
  author={Makridakis, Spyros},
  journal={Futures},
  volume={90},
  pages={46--60},
  year={2017},
  publisher={Elsevier}
}

@article{zhang2010cloud,
  title={Cloud computing: state-of-the-art and research challenges},
  author={Zhang, Qi and Cheng, Lu and Boutaba, Raouf},
  journal={Journal of internet services and applications},
  volume={1},
  pages={7--18},
  year={2010},
  publisher={Springer}
}

@inproceedings{shokri2017membership,
  title={Membership inference attacks against machine learning models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle={2017 IEEE symposium on security and privacy (SP)},
  pages={3--18},
  year={2017},
  organization={IEEE}
}

@inproceedings{wang2018stealing,
  title={Stealing hyperparameters in machine learning},
  author={Wang, Binghui and Gong, Neil Zhenqiang},
  booktitle={2018 IEEE symposium on security and privacy (SP)},
  pages={36--52},
  year={2018},
  organization={IEEE}
}

@article{fu2020vfl,
  title={VFL: A verifiable federated learning with privacy-preserving for big data in industrial IoT},
  author={Fu, Anmin and Zhang, Xianglong and Xiong, Naixue and Gao, Yansong and Wang, Huaqun and Zhang, Jing},
  journal={IEEE Transactions on Industrial Informatics},
  volume={18},
  number={5},
  pages={3316--3326},
  year={2020},
  publisher={IEEE}
}

@article{yang2012efficient,
  title={An efficient and secure dynamic auditing protocol for data storage in cloud computing},
  author={Yang, Kan and Jia, Xiaohua},
  journal={IEEE transactions on parallel and distributed systems},
  volume={24},
  number={9},
  pages={1717--1726},
  year={2012},
  publisher={Ieee}
}

@inproceedings{kerschbaum2012outsourced,
  title={Outsourced private set intersection using homomorphic encryption},
  author={Kerschbaum, Florian},
  booktitle={Proceedings of the 7th ACM Symposium on Information, Computer and Communications Security},
  pages={85--86},
  year={2012}
}

@article{li2015encdb,
  title={L-EncDB: A lightweight framework for privacy-preserving data queries in cloud computing},
  author={Li, Jin and Liu, Zheli and Chen, Xiaofeng and Xhafa, Fatos and Tan, Xiao and Wong, Duncan S},
  journal={Knowledge-Based Systems},
  volume={79},
  pages={18--26},
  year={2015},
  publisher={Elsevier}
}

@article{van2014datafication,
  title={Datafication, dataism and dataveillance: Big Data between scientific paradigm and ideology},
  author={Van Dijck, Jos{\'e}},
  journal={Surveillance \& society},
  volume={12},
  number={2},
  pages={197--208},
  year={2014}
}

@article{cui2018security,
  title={Security and privacy in smart cities: Challenges and opportunities},
  author={Cui, Lei and Xie, Gang and Qu, Youyang and Gao, Longxiang and Yang, Yunyun},
  journal={IEEE access},
  volume={6},
  pages={46134--46145},
  year={2018},
  publisher={IEEE}
}

@inproceedings{mohassel2017secureml,
  title={Secureml: A system for scalable privacy-preserving machine learning},
  author={Mohassel, Payman and Zhang, Yupeng},
  booktitle={2017 IEEE symposium on security and privacy (SP)},
  pages={19--38},
  year={2017},
  organization={IEEE}
}



@article{mao2017survey,
  title={A survey on mobile edge computing: The communication perspective},
  author={Mao, Yuyi and You, Changsheng and Zhang, Jun and Huang, Kaibin and Letaief, Khaled B},
  journal={IEEE communications surveys \& tutorials},
  volume={19},
  number={4},
  pages={2322--2358},
  year={2017},
  publisher={IEEE}
}

@inproceedings{gentry2009fully,
  title={Fully homomorphic encryption using ideal lattices},
  author={Gentry, Craig},
  booktitle={Proceedings of the forty-first annual ACM symposium on Theory of computing},
  pages={169--178},
  year={2009}
}

@inproceedings{xu2019cryptonn,
  title={Cryptonn: Training neural networks over encrypted data},
  author={Xu, Runhua and Joshi, James BD and Li, Chao},
  booktitle={2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)},
  pages={1199--1209},
  year={2019},
  organization={IEEE}
}

@inproceedings{cheon2017homomorphic,
  title={Homomorphic encryption for arithmetic of approximate numbers},
  author={Cheon, Jung Hee and Kim, Andrey and Kim, Miran and Song, Yongsoo},
  booktitle={Advances in Cryptology--ASIACRYPT 2017: 23rd International Conference on the Theory and Applications of Cryptology and Information Security, Hong Kong, China, December 3-7, 2017, Proceedings, Part I 23},
  pages={409--437},
  year={2017},
  organization={Springer}
}

@inproceedings{gilad2016cryptonets,
  title={Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy},
  author={Gilad-Bachrach, Ran and Dowlin, Nathan and Laine, Kim and Lauter, Kristin and Naehrig, Michael and Wernsing, John},
  booktitle={International conference on machine learning},
  pages={201--210},
  year={2016},
  organization={PMLR}
}


@inproceedings{bogdanov2008sharemind,
  title={Sharemind: A framework for fast privacy-preserving computations},
  author={Bogdanov, Dan and Laur, Sven and Willemson, Jan},
  booktitle={Computer Security-ESORICS 2008: 13th European Symposium on Research in Computer Security, M{\'a}laga, Spain, October 6-8, 2008. Proceedings 13},
  pages={192--206},
  year={2008},
  organization={Springer}
}



@inproceedings{10.1145/3319535.3339819,
author = {Agrawal, Nitin and Shahin Shamsabadi, Ali and Kusner, Matt J. and Gasc\'{o}n, Adri\`{a}},
title = {QUOTIENT: Two-Party Secure Neural Network Training and Prediction},
year = {2019},
isbn = {9781450367479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3319535.3339819},
doi = {10.1145/3319535.3339819},
abstract = {Recently, there has been a wealth of effort devoted to the design of secure protocols for machine learning tasks. Much of this is aimed at enabling secure prediction from highly-accurate Deep Neural Networks (DNNs). However, as DNNs are trained on data, a key question is how such models can be also trained securely. The few prior works on secure DNN training have focused either on designing custom protocols for existing training algorithms, or on developing tailored training algorithms and then applying generic secure protocols. In this work, we investigate the advantages of designing training algorithms alongside a novel secure protocol, incorporating optimizations on both fronts. We present QUOTIENT, a new method for discretized training of DNNs, along with a customized secure two-party protocol for it. QUOTIENT incorporates key components of state-of-the-art DNN training such as layer normalization and adaptive gradient methods, and improves upon the state-of-the-art in DNN training in two-party computation. Compared to prior work, we obtain an improvement of 50X in WAN time and 6\% in absolute accuracy.},
booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1231–1247},
numpages = {17},
keywords = {secure multi-party computation, quantized deep neural networks, privacy-preserving deep learning},
location = {London, United Kingdom},
series = {CCS '19}
}


@inproceedings{10.1145/3243734.3243760,
author = {Mohassel, Payman and Rindal, Peter},
title = {ABY3: A Mixed Protocol Framework for Machine Learning},
year = {2018},
isbn = {9781450356930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3243734.3243760},
doi = {10.1145/3243734.3243760},
abstract = {Machine learning is widely used to produce models for a range of applications and is increasingly offered as a service by major technology companies. However, the required massive data collection raises privacy concerns during both training and prediction stages. In this paper, we design and implement a general framework for privacy-preserving machine learning and use it to obtain new solutions for training linear regression, logistic regression and neural network models. Our protocols are in a three-server model wherein data owners secret share their data among three servers who train and evaluate models on the joint data using three-party computation (3PC). Our main contribution is a new and complete framework ($textABY ^3$) for efficiently switching back and forth between arithmetic, binary, and Yao 3PC which is of independent interest. Many of the conversions are based on new techniques that are designed and optimized for the first time in this paper. We also propose new techniques for fixed-point multiplication of shared decimal values that extends beyond the three-party case, and customized protocols for evaluating piecewise polynomial functions. We design variants of each building block that is secure against em malicious adversaries who deviate arbitrarily. We implement our system in C++. Our protocols are up to em four orders of magnitude faster than the best prior work, hence significantly reducing the gap between privacy-preserving and plaintext training.},
booktitle = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},
pages = {35–52},
numpages = {18},
keywords = {gradient descent, inference, logistic regression, machine learning, neural networks, regression, secure multi-party computation, secure protocol, training},
location = {Toronto, Canada},
series = {CCS '18}
}


@misc{cryptoeprint:2020/042,
      author = {Arpita Patra and Ajith Suresh},
      title = {{BLAZE}: Blazing Fast Privacy-Preserving Machine Learning},
      howpublished = {Cryptology {ePrint} Archive, Paper 2020/042},
      year = {2020},
      doi = {10.14722/ndss.2020.24202},
      url = {https://eprint.iacr.org/2020/042}
}


@inproceedings{10.1145/3196494.3196522,
author = {Riazi, M. Sadegh and Weinert, Christian and Tkachenko, Oleksandr and Songhori, Ebrahim M. and Schneider, Thomas and Koushanfar, Farinaz},
title = {Chameleon: A Hybrid Secure Computation Framework for Machine Learning Applications},
year = {2018},
isbn = {9781450355766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196494.3196522},
doi = {10.1145/3196494.3196522},
abstract = {We present Chameleon, a novel hybrid (mixed-protocol) framework for secure function evaluation (SFE) which enables two parties to jointly compute a function without disclosing their private inputs. Chameleon combines the best aspects of generic SFE protocols with the ones that are based upon additive secret sharing. In particular, the framework performs linear operations in the ring $mathbbZ _2^l $ using additively secret shared values and nonlinear operations using Yao's Garbled Circuits or the Goldreich-Micali-Wigderson protocol. Chameleon departs from the common assumption of additive or linear secret sharing models where three or more parties need to communicate in the online phase: the framework allows two parties with private inputs to communicate in the online phase under the assumption of a third node generating correlated randomness in an offline phase. Almost all of the heavy cryptographic operations are precomputed in an offline phase which substantially reduces the communication overhead. Chameleon is both scalable and significantly more efficient than the ABY framework (NDSS'15) it is based on. Our framework supports signed fixed-point numbers. In particular, Chameleon's vector dot product of signed fixed-point numbers improves the efficiency of mining and classification of encrypted data for algorithms based upon heavy matrix multiplications. Our evaluation of Chameleon on a 5 layer convolutional deep neural network shows 133x and 4.2x faster executions than Microsoft CryptoNets (ICML'16) and MiniONN (CCS'17), respectively.},
booktitle = {Proceedings of the 2018 on Asia Conference on Computer and Communications Security},
pages = {707–721},
numpages = {15},
keywords = {deep neural networks, garbled circuits, machine learning, secret sharing, secure computation},
location = {Incheon, Republic of Korea},
series = {ASIACCS '18}
}

@article{Tian2022SphinxEP,
  title={Sphinx: Enabling Privacy-Preserving Online Learning over the Cloud},
  author={Han Tian and Chaoliang Zeng and Zhenghang Ren and Di Chai and Junxue Zhang and Kai Chen and Qian Yang},
  journal={2022 IEEE Symposium on Security and Privacy (SP)},
  year={2022},
  pages={2487-2501},
  url={https://api.semanticscholar.org/CorpusID:251146012}
}


@inproceedings{NIPS2012_c399862d,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@INPROCEEDINGS{7780459,
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Deep Residual Learning for Image Recognition}, 
  year={2016},
  volume={},
  number={},
  pages={770-778},
  keywords={Training;Degradation;Complexity theory;Image recognition;Neural networks;Visualization;Image segmentation},
  doi={10.1109/CVPR.2016.90}}

@INPROCEEDINGS{8099726,
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q.},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Densely Connected Convolutional Networks}, 
  year={2017},
  volume={},
  number={},
  pages={2261-2269},
  keywords={Training;Convolution;Network architecture;Convolutional codes;Neural networks;Road transportation},
  doi={10.1109/CVPR.2017.243}}


@article{krizhevsky2009learning,
  added-at = {2021-01-21T03:01:11.000+0100},
  author = {Krizhevsky, Alex},
  biburl = {https://www.bibsonomy.org/bibtex/2fe5248afe57647d9c85c50a98a12145c/s364315},
  interhash = {cc2d42f2b7ef6a4e76e47d1a50c8cd86},
  intrahash = {fe5248afe57647d9c85c50a98a12145c},
  keywords = {},
  pages = {32--33},
  timestamp = {2021-01-21T03:01:11.000+0100},
  title = {Learning Multiple Layers of Features from Tiny Images},
  url = {https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf},
  year = 2009
}


@InProceedings{pmlr-v54-mcmahan17a,
  title = 	 {{Communication-Efficient Learning of Deep Networks from Decentralized Data}},
  author = 	 {McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and Arcas, Blaise Aguera y},
  booktitle = 	 {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1273--1282},
  year = 	 {2017},
  editor = 	 {Singh, Aarti and Zhu, Jerry},
  volume = 	 {54},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {20--22 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v54/mcmahan17a/mcmahan17a.pdf},
  url = 	 {https://proceedings.mlr.press/v54/mcmahan17a.html},
  abstract = 	 {Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches.  We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning.  We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10-100x as compared to synchronized stochastic gradient descent. }
}


@misc{konečný2018federated,
title={Federated Learning: Strategies for Improving Communication Efficiency},
author={Jakub Konečný and H. Brendan McMahan and Felix X. Yu and Ananda Theertha Suresh and Dave Bacon and Peter Richtárik},
year={2018},
url={https://openreview.net/forum?id=B1EPYJ-C-},
}

@article{Gupta2018DistributedLO,
  title={Distributed learning of deep neural network over multiple agents},
  author={Otkrist Gupta and Ramesh Raskar},
  journal={ArXiv},
  year={2018},
  volume={abs/1810.06060},
  url={https://api.semanticscholar.org/CorpusID:49675958}
}

@INPROCEEDINGS{9252066,
  author={Gao, Yansong and Kim, Minki and Abuadbba, Sharif and Kim, Yeonjae and Thapa, Chandra and Kim, Kyuyeon and Camtep, Seyit A. and Kim, Hyoungshick and Nepal, Surya},
  booktitle={2020 International Symposium on Reliable Distributed Systems (SRDS)}, 
  title={End-to-End Evaluation of Federated Learning and Split Learning for Internet of Things}, 
  year={2020},
  volume={},
  number={},
  pages={91-100},
  keywords={Performance evaluation;Training;Power demand;Distributed databases;Machine learning;Internet of Things;Convergence;split learning;federated learning;distributed machine learning;IoT},
  doi={10.1109/SRDS51746.2020.00017}}
  
  @INPROCEEDINGS{7958569,
  author={Mohassel, Payman and Zhang, Yupeng},
  booktitle={2017 IEEE Symposium on Security and Privacy (SP)}, 
  title={SecureML: A System for Scalable Privacy-Preserving Machine Learning}, 
  year={2017},
  volume={},
  number={},
  pages={19-38},
  keywords={Training;Logistics;Protocols;Data models;Privacy;Linear regression;Neural networks;Privacy-preserving machine learning;secure computation},
  doi={10.1109/SP.2017.12}}

@article{Rachuri2019TridentE4,
  title={Trident: Efficient 4PC Framework for Privacy Preserving Machine Learning},
  author={Rahul Rachuri and Ajith Suresh},
  journal={IACR Cryptol. ePrint Arch.},
  year={2019},
  volume={2019},
  pages={1315},
  url={https://api.semanticscholar.org/CorpusID:208179672}
}

@article{Escudero2020ImprovedPF,
  title={Improved Primitives for MPC over Mixed Arithmetic-Binary Circuits},
  author={Daniel E. Escudero and Satrajit Ghosh and Marcel Keller and Rahul Rachuri and Peter Scholl},
  journal={IACR Cryptol. ePrint Arch.},
  year={2020},
  volume={2020},
  pages={338},
  url={https://api.semanticscholar.org/CorpusID:214642454}
}

@article{Dalskov2020FantasticFH,
  title={Fantastic Four: Honest-Majority Four-Party Secure Computation With Malicious Security},
  author={Anders Dalskov and Daniel E. Escudero and Marcel Keller},
  journal={IACR Cryptol. ePrint Arch.},
  year={2020},
  volume={2020},
  pages={1330},
  url={https://api.semanticscholar.org/CorpusID:226203118}
}

@article{Nandakumar2019TowardsDN,
  title={Towards Deep Neural Network Training on Encrypted Data},
  author={Karthik Nandakumar and Nalini K. Ratha and Sharath Pankanti and Shai Halevi},
  journal={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  year={2019},
  pages={40-48},
  url={https://api.semanticscholar.org/CorpusID:198165271}
}


@article{CiC-1-2-22,
    author = "Bkakria, Anis and Izabachène, Malika",
    journal = "{IACR} {C}ommunications in {C}ryptology",
    publisher = "{I}nternational {A}ssociation for {C}ryptologic {R}esearch",
    title = "Efficient Post-Quantum Pattern Matching on Encrypted Data",
    volume = "1",
    number = "2",
    date = "2024-07-08",
    year = "2024",
    issn = "3006-5496",
    doi = "10.62056/a09qxrxqi"
}
@inproceedings {279898,
author = {Zhicong Huang and Wen-jie Lu and Cheng Hong and Jiansheng Ding},
title = {Cheetah: Lean and Fast Secure {Two-Party} Deep Neural Network Inference},
booktitle = {31st USENIX Security Symposium (USENIX Security 22)},
year = {2022},
isbn = {978-1-939133-31-1},
address = {Boston, MA},
pages = {809--826},
url = {https://www.usenix.org/conference/usenixsecurity22/presentation/huang-zhicong},
publisher = {USENIX Association},
month = aug
}
@article{zhao2023identifiable,
  title={Identifiable, but not visible: A privacy-preserving person reidentification scheme},
  author={Zhao, Bowen and Li, Yingjiu and Liu, Ximeng and Li, Xiaoguo and Pang, Hwee Hwa and Deng, Robert H},
  journal={IEEE Transactions on Reliability},
  volume={72},
  number={4},
  pages={1295--1307},
  year={2023},
  publisher={IEEE}
}
@INPROCEEDINGS{9888863,
  author={Zhao, Bowen and Li, Yingjiu and Liu, Ximeng and Pang, Hwee Hwa and Deng, Robert H.},
  booktitle={2022 IEEE Conference on Dependable and Secure Computing (DSC)}, 
  title={FREED: An Efficient Privacy-Preserving Solution for Person Re-IDentification}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  keywords={Support vector machines;Privacy;Data privacy;Protocols;Costs;Surveillance;Computer architecture;person Re-IDentification;image privacy;secure computing;threshold homomorphism},
  doi={10.1109/DSC54232.2022.9888863}}
